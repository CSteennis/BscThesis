{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNN on MNIST\n",
    "\n",
    "In this notebook I train a Spiking Neural network on the MNIST dataset\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/{user_name}/{repo_name}/blob/{branch_name}/mnist.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install snntorch\n",
    "%pip install torchmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.functional as sf\n",
    "import torch.functional as tsf\n",
    "import snntorch as snn\n",
    "from snntorch import spikegen\n",
    "import torch, torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import savgol_filter\n",
    "import numpy as np\n",
    "\n",
    "from torchmetrics.classification import MulticlassAccuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spiking Network\n",
    "\n",
    "Here I define the spiking network with leaky neurons in the hidden and output layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    '''Spiking Neural network'''\n",
    "    def __init__(self, num_inputs, num_hiddens, num_outputs, beta, num_steps, enc_type):\n",
    "        super().__init__()\n",
    "\n",
    "        self.enc_type = enc_type\n",
    "\n",
    "        self.num_inputs = num_inputs # number of inputs\n",
    "        self.num_hidden = num_hiddens # number of hidden neurons\n",
    "        self.num_outputs = num_outputs # number of output neurons\n",
    "\n",
    "        self.num_steps = num_steps # number of timesteps per sample\n",
    "\n",
    "        # initialize layers\n",
    "        self.fc1 = nn.Linear(self.num_inputs, self.num_hidden) # connection input and hidden layer\n",
    "        self.lif1 = snn.Leaky(beta=beta) # hidden layer\n",
    "        self.fc2 = nn.Linear(self.num_hidden, self.num_outputs) # connection hidden layer and output\n",
    "        self.lif2 = snn.Leaky(beta=beta) # output layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        '''Run the network for ``num_steps`` with ``data`` as input. Output spiketrains of outputs'''\n",
    "        # initialize membrane potentials for hidden and output layer\n",
    "        mem_hid = self.lif1.init_leaky()\n",
    "        mem_out = self.lif1.init_leaky()\n",
    "\n",
    "        spike_out_rec = []\n",
    "\n",
    "        data = self.gen_spike_trains(data, self.num_steps)\n",
    "\n",
    "        for i in range(self.num_steps):\n",
    "            input = self.fc1(data[i])\n",
    "            spike_hid, mem_hid = self.lif1(input, mem_hid)\n",
    "            hidden_out = self.fc2(spike_hid)\n",
    "            spike_out, mem_out = self.lif2(hidden_out, mem_out)\n",
    "\n",
    "            spike_out_rec.append(spike_out)\n",
    "\n",
    "        return torch.stack(spike_out_rec)\n",
    "    \n",
    "    def gen_spike_trains(self, data, n_steps):\n",
    "        ''' Generate spike train\n",
    "            In: [num_steps, batch, input_size]\n",
    "            Out: [num_steps, batch, input_size]\n",
    "        '''\n",
    "\n",
    "        if self.enc_type == 'rate':\n",
    "            spike_data = spikegen.rate(data, num_steps=n_steps)\n",
    "        if self.enc_type == 'latency':\n",
    "            spike_data = spikegen.latency(data, num_steps=n_steps)\n",
    "        else:\n",
    "            return None\n",
    "            # throw('type unknown')\n",
    "        return spike_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions to import data and plot the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def import_data():\n",
    "    # Define a transform\n",
    "    transform = transforms.Compose([\n",
    "                transforms.Resize((28,28)),\n",
    "                transforms.Grayscale(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0,), (1,))])\n",
    "\n",
    "    mnist_train = datasets.MNIST(\"/dataset/\", train=True, download=True, transform=transform)\n",
    "    mnist_test = datasets.MNIST(\"/dataset/\", train=False, download=True, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(mnist_train, batch_size=128, shuffle=True)\n",
    "    test_loader = DataLoader(mnist_test, batch_size=64) \n",
    "    \n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_accuracy(acc_hist, title, test=False):\n",
    "    plt.plot(acc_hist)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Epoch\" if test else \"Batch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    # plt.savefig(title+\".png\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss(loss_hist, title):\n",
    "    plt.plot(loss_hist)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Batch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    # plt.savefig(title+\".png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_accuracy(data_loader, net, accuracy):\n",
    "  with torch.no_grad():\n",
    "    total = 0\n",
    "    acc = 0\n",
    "    net.eval()\n",
    "\n",
    "    data_loader = iter(data_loader)\n",
    "    for data, targets in data_loader:\n",
    "      spk_rec = net(data.squeeze().flatten(1))\n",
    "\n",
    "      acc += accuracy(spk_rec, targets) * spk_rec.size(1)\n",
    "      total += spk_rec.size(1)\n",
    "\n",
    "  return acc/total\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train loop for the snn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(net:nn.Module, optimizer, loss_fn, accuracy, train_loader, test_loader, epochs):\n",
    "    '''Training loop for snn'''\n",
    "\n",
    "    acc_hist = []\n",
    "    loss_hist = []\n",
    "    test_acc_hist = []\n",
    "    acc_per_epoch = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        with tqdm(train_loader, unit=\"batch\") as tqepch:\n",
    "            tqepch.set_description(desc=f\"Epoch {epoch}\")\n",
    "            for data, label in tqepch:\n",
    "                # set net to training mode\n",
    "                net.train()\n",
    "\n",
    "                data = data.squeeze().flatten(1)\n",
    "\n",
    "                # do forward pass\n",
    "                output = net(data)\n",
    "\n",
    "                # calculate loss value\n",
    "                loss_val = loss_fn(output, label)\n",
    "                loss_hist.append(loss_val.item())\n",
    "\n",
    "                # clear previously stored gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # calculate the gradients\n",
    "                loss_val.backward()\n",
    "\n",
    "                # weight update\n",
    "                optimizer.step()\n",
    "\n",
    "                # determine batch accuracy\n",
    "                acc = accuracy(output, label)\n",
    "                acc_hist.append(acc)\n",
    "\n",
    "                tqepch.set_postfix(loss=loss_val.item(), accuracy=f'{acc * 100:.2f}')\n",
    "\n",
    "        # accuracy per epoch\n",
    "        acc_per_epoch.append(acc_hist)\n",
    "\n",
    "        # accuracy on test set for epoch\n",
    "        test_acc = test_accuracy(test_loader, net, accuracy)\n",
    "        test_acc_hist.append(test_acc)\n",
    "        \n",
    "        print(f'Test accuracy: {test_acc * 100:.2f}%')\n",
    "\n",
    "    # take the mean of all the epochs\n",
    "    acc_per_epoch = np.mean(acc_per_epoch, axis=0)\n",
    "    \n",
    "    # smoothing\n",
    "    acc_per_epoch = savgol_filter(acc_per_epoch,10,1)\n",
    "    loss_hist = savgol_filter(loss_hist,10,1)\n",
    "\n",
    "    # plot\n",
    "    # plot_accuracy(acc_per_epoch, \"Train accuracy\", 1)\n",
    "    # plot_loss(loss_hist, \"Train loss\", 2)\n",
    "    # plot_accuracy(test_acc_hist, \"Test accuracy\", 3, test=True)\n",
    "\n",
    "    # return trained network\n",
    "    return net, test_acc_hist\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# number of epochs\n",
    "epochs = 1\n",
    "\n",
    "# number of time steps\n",
    "n_steps = 25 #ms\n",
    "\n",
    "# neuron counts\n",
    "inputs = 28 * 28\n",
    "hiddens = 200\n",
    "outputs = 10\n",
    "\n",
    "# import training and test data\n",
    "train_loader, test_loader = import_data()\n",
    "\n",
    "# membrane potential decay\n",
    "decay = 0.9\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train command for the snn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"SNN rate:\")\n",
    "\n",
    "# initialize net\n",
    "net = Net(inputs, hiddens, outputs, decay, n_steps, 'rate')\n",
    "\n",
    "# optimization algoritm\n",
    "optimizer = torch.optim.Adam(net.parameters()) # (NOTE: Adam stond in de tutorial misschien beter algoritme)\n",
    "\n",
    "# loss function\n",
    "loss_fn = sf.ce_count_loss() # type: ignore\n",
    "\n",
    "accuracy = sf.accuracy_rate\n",
    "\n",
    "trained_snn_rate, test_acc_snn_rate = train(net, optimizer, loss_fn, accuracy, train_loader, test_loader, epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"SNN temporal:\")\n",
    "\n",
    "# initialize net\n",
    "net = Net(inputs, hiddens, outputs, decay, n_steps, 'latency')\n",
    "\n",
    "# optimization algoritm\n",
    "optimizer = torch.optim.Adam(net.parameters()) # (NOTE: Adam stond in de tutorial misschien beter algoritme)\n",
    "\n",
    "# loss function\n",
    "loss_fn = sf.ce_temporal_loss() # type: ignore\n",
    "\n",
    "accuracy = sf.accuracy_temporal\n",
    "\n",
    "trained_snn_temp, test_acc_snn_temp = train(net, optimizer, loss_fn, accuracy, train_loader, test_loader, epochs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test net on single img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = next(iter(train_loader))[0].squeeze()\n",
    "\n",
    "img = 0\n",
    "\n",
    "plt.imshow(data[img],cmap=\"Greys\")\n",
    "\n",
    "output = net.forward(data.flatten(1))\n",
    "\n",
    "fig, ax = plt.subplots(5,2)\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(2):\n",
    "        ax[i][j].plot(output[:,img,2*i+j].detach().numpy())\n",
    "        ax[i][j].set_title(f'{2*i+j}')\n",
    "        ax[i][j].set_ybound(-0.2,1.2)\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train command for Feed Forward net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feed_fwd_net = nn.Sequential(nn.Linear(inputs, hiddens),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(hiddens, outputs))\n",
    "\n",
    "# optimization algoritm\n",
    "optimizer = torch.optim.Adam(feed_fwd_net.parameters()) # (NOTE: Adam stond in de tutorial misschien beter algoritme)\n",
    "\n",
    "# loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "accuracy = MulticlassAccuracy(num_classes=outputs)\n",
    "\n",
    "print(\"FFN:\")\n",
    "trained_feed_fwd, test_acc_feed = train(feed_fwd_net, optimizer, loss_fn, accuracy, train_loader, test_loader, epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot_accuracy(test_acc_feed, \"Test accuracy\", 3, test=True)\n",
    "\n",
    "# fig = plt.figure(3)\n",
    "\n",
    "fig = plt.figure(1)\n",
    "plt.plot(test_acc_snn_rate, label=\"SNN rate\")\n",
    "plt.plot(test_acc_snn_temp, label=\"SNN temporal\")\n",
    "plt.plot(test_acc_feed, label=\"FFN\")\n",
    "plt.title(\"Test accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "# plt.savefig(title+\".png\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "nbformat": 4,
  "nbformat_minor": 0
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
